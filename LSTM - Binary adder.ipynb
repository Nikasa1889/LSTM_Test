{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "#add binary string a, and b to create c.\n",
    "def add(a, b):\n",
    "    l = max(len(a), len(b));\n",
    "    a = int(a, 2);\n",
    "    b = int(b, 2);\n",
    "    c = bin(a+b)[2:].zfill(l);\n",
    "    return c;\n",
    "\n",
    "def str2np(a):\n",
    "    result = [int(x) for x in a]\n",
    "    return result;\n",
    "\n",
    "def lstofstr2tensor(lstofstr):\n",
    "    tensor = [str2np(string) for string in lstofstr]\n",
    "    return tensor\n",
    "\n",
    "def merge_str2list(str1, str2):\n",
    "    result = [[int(str1[i]), int(str2[i])] for i in xrange(len(str1))]\n",
    "    return result\n",
    "N_bit = 15;\n",
    "#To prevent overloading bit on result, we only generate N_bit-1 string\n",
    "formatting_string = ('{0:0'+str(N_bit)+'b}')\n",
    "input_a = [formatting_string.format(i) for i in xrange(2**(N_bit-1))];\n",
    "input_b = [formatting_string.format(i) for i in xrange(2**(N_bit-1))];\n",
    "shuffle(input_a);\n",
    "shuffle(input_b);\n",
    "\n",
    "N_TOTAL = 2000;\n",
    "\n",
    "input_a = input_a[:N_TOTAL];\n",
    "input_b = input_b[:N_TOTAL];\n",
    "target_c = [add(input_a[i], input_b[i]) for i in xrange(N_TOTAL)];\n",
    "\n",
    "#Need to reverse the binary string, since we do the calculation from right to left\n",
    "input_a = [a[::-1] for a in input_a];\n",
    "input_b = [b[::-1] for b in input_b];\n",
    "target_c = [c[::-1] for c in target_c];\n",
    "\n",
    "#Merge string a and b to one input\n",
    "input_ab = [merge_str2list(input_a[i], input_b[i]) for i in xrange(N_TOTAL)];\n",
    "\n",
    "target_c = lstofstr2tensor(target_c);\n",
    "\n",
    "#Convert to numpy array\n",
    "input_ab = np.asarray(input_ab)\n",
    "target_c = np.asarray(target_c)\n",
    "\n",
    "#Split to training and testing dataset\n",
    "N_TRAIN = 1500;\n",
    "test_input_ab = input_ab[N_TRAIN:]\n",
    "test_target_c = target_c[N_TRAIN:] \n",
    "\n",
    "train_input_ab = input_ab[:N_TRAIN]\n",
    "train_target_c = target_c[:N_TRAIN] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tensorflow for LSTM\n",
    "#### First we define the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Placeholder for input and target, [Batch Size, Sequence Length, Input Dimension]\n",
    "data = tf.placeholder(tf.float32, [None, N_bit, 2])\n",
    "target = tf.placeholder(tf.float32, [None, N_bit])\n",
    "\n",
    "num_hidden = 5\n",
    "time_steps = N_bit\n",
    "\n",
    "lstmCell = tf.nn.rnn_cell.BasicLSTMCell(num_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "\n",
    "#sequence_length \n",
    "#unroll the LSTM network\n",
    "outputs, states = tf.nn.dynamic_rnn(cell=lstmCell, inputs=data, dtype=tf.float32)\n",
    "\n",
    "# Define weights\n",
    "out_size = 1;\n",
    "\n",
    "# Weights for each timestep output, using the same weight\n",
    "weight = tf.Variable(tf.truncated_normal([num_hidden, out_size], stddev=0.1))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[out_size]))\n",
    "\n",
    "outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "prediction = tf.sigmoid(tf.matmul(outputs, weight) + bias)\n",
    "prediction = tf.reshape(prediction, [-1, time_steps, out_size])\n",
    "prediction = tf.squeeze(prediction)\n",
    "\n",
    "cross_entropy = -tf.reduce_mean(target * tf.log(prediction) + (1-target)*tf.log(1-prediction))\n",
    "#cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#cross_entropy = -tf.reduce_sum(target * tf.log(prediction))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "minimize = optimizer.minimize(cross_entropy)\n",
    "\n",
    "final_prediction = prediction>0.5;\n",
    "mistakes = tf.not_equal(target>0.5, final_prediction) #careful when target is still float32\n",
    "error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then we execute the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11486697197 s Epoch -  0\n",
      "0.207987785339 s Epoch -  1\n",
      "0.338280916214 s Epoch -  2\n",
      "0.442290782928 s Epoch -  3\n",
      "0.542657852173 s Epoch -  4\n",
      "0.670880794525 s Epoch -  5\n",
      "0.803787946701 s Epoch -  6\n",
      "0.924484968185 s Epoch -  7\n",
      "1.05669093132 s Epoch -  8\n",
      "1.15876889229 s Epoch -  9\n",
      "1.26035785675 s Epoch -  10\n",
      "1.37217998505 s Epoch -  11\n",
      "1.47968888283 s Epoch -  12\n",
      "1.58044195175 s Epoch -  13\n",
      "1.69077682495 s Epoch -  14\n",
      "1.801831007 s Epoch -  15\n",
      "1.92599081993 s Epoch -  16\n",
      "2.02308893204 s Epoch -  17\n",
      "2.13217687607 s Epoch -  18\n",
      "2.2464017868 s Epoch -  19\n",
      "2.37060880661 s Epoch -  20\n",
      "2.46777486801 s Epoch -  21\n",
      "2.57704401016 s Epoch -  22\n",
      "2.69517493248 s Epoch -  23\n",
      "2.81639289856 s Epoch -  24\n",
      "2.92856478691 s Epoch -  25\n",
      "3.04765200615 s Epoch -  26\n",
      "3.14871692657 s Epoch -  27\n",
      "3.24510478973 s Epoch -  28\n",
      "3.36249399185 s Epoch -  29\n",
      "3.46630096436 s Epoch -  30\n",
      "3.57252192497 s Epoch -  31\n",
      "3.68522286415 s Epoch -  32\n",
      "3.79923391342 s Epoch -  33\n",
      "3.90945696831 s Epoch -  34\n",
      "4.01765990257 s Epoch -  35\n",
      "4.12159991264 s Epoch -  36\n",
      "4.25862383842 s Epoch -  37\n",
      "4.50893092155 s Epoch -  38\n",
      "4.7395567894 s Epoch -  39\n",
      "4.97211194038 s Epoch -  40\n",
      "5.11920881271 s Epoch -  41\n",
      "5.24595594406 s Epoch -  42\n",
      "5.35025882721 s Epoch -  43\n",
      "5.45140790939 s Epoch -  44\n",
      "5.57142496109 s Epoch -  45\n",
      "5.68808889389 s Epoch -  46\n",
      "5.78777098656 s Epoch -  47\n",
      "5.88586497307 s Epoch -  48\n",
      "6.01474499702 s Epoch -  49\n",
      "6.11244893074 s Epoch -  50\n",
      "6.21349978447 s Epoch -  51\n",
      "6.34000778198 s Epoch -  52\n",
      "6.47019290924 s Epoch -  53\n",
      "6.70771288872 s Epoch -  54\n",
      "6.88332080841 s Epoch -  55\n",
      "7.02976989746 s Epoch -  56\n",
      "7.14041399956 s Epoch -  57\n",
      "7.24291396141 s Epoch -  58\n",
      "7.36038780212 s Epoch -  59\n",
      "7.47767782211 s Epoch -  60\n",
      "7.58924889565 s Epoch -  61\n",
      "7.69510197639 s Epoch -  62\n",
      "7.80346083641 s Epoch -  63\n",
      "7.9094479084 s Epoch -  64\n",
      "8.02907681465 s Epoch -  65\n",
      "8.14693593979 s Epoch -  66\n",
      "8.24615597725 s Epoch -  67\n",
      "8.35001683235 s Epoch -  68\n",
      "8.46828889847 s Epoch -  69\n",
      "8.58563685417 s Epoch -  70\n",
      "8.6855609417 s Epoch -  71\n",
      "8.79803800583 s Epoch -  72\n",
      "8.91856098175 s Epoch -  73\n",
      "9.06882381439 s Epoch -  74\n",
      "9.19807481766 s Epoch -  75\n",
      "9.33277487755 s Epoch -  76\n",
      "9.43187785149 s Epoch -  77\n",
      "9.53396582603 s Epoch -  78\n",
      "9.65840482712 s Epoch -  79\n",
      "9.79493999481 s Epoch -  80\n",
      "9.90378189087 s Epoch -  81\n",
      "10.0151548386 s Epoch -  82\n",
      "10.1391849518 s Epoch -  83\n",
      "10.2534308434 s Epoch -  84\n",
      "10.3609578609 s Epoch -  85\n",
      "10.4666688442 s Epoch -  86\n",
      "10.5869138241 s Epoch -  87\n",
      "10.7118029594 s Epoch -  88\n",
      "10.8131799698 s Epoch -  89\n",
      "10.9186758995 s Epoch -  90\n",
      "11.0195069313 s Epoch -  91\n",
      "11.1298189163 s Epoch -  92\n",
      "11.2291128635 s Epoch -  93\n",
      "11.3366439342 s Epoch -  94\n",
      "11.4619338512 s Epoch -  95\n",
      "11.5885570049 s Epoch -  96\n",
      "11.694578886 s Epoch -  97\n",
      "11.8087508678 s Epoch -  98\n",
      "11.9270048141 s Epoch -  99\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "no_of_batches = int(len(train_input_ab)/BATCH_SIZE)\n",
    "epoch = 200\n",
    "start = time.time();\n",
    "for i in range(epoch):\n",
    "    ptr = 0\n",
    "    for j in range(no_of_batches):\n",
    "        inp, out = train_input_ab[ptr:ptr+BATCH_SIZE], train_target_c[ptr:ptr+BATCH_SIZE]\n",
    "        ptr+=BATCH_SIZE\n",
    "        sess.run(minimize,{data: inp, target: out})\n",
    "        \n",
    "        #print(sess.run(cross_entropy,{data: inp, target: out}))\n",
    "    print str(time.time()-start), \"s Epoch - \", str(i);\n",
    "incorrect = sess.run(error,{data: test_input_ab, target: test_target_c})\n",
    "print('Epoch {:2d} error {:3.1f}%'.format(i + 1, 100 * incorrect))\n",
    "prediction = sess.run(final_prediction,{data: test_input_ab, target: test_target_c})\n",
    "prediction.astype(int)\n",
    "\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]]\n",
      "[0 1 1 0 0 0 1 0 0 0 1 0 1 0 1]\n",
      "[False  True  True False False False  True False False False  True False\n",
      "  True False  True]\n"
     ]
    }
   ],
   "source": [
    "#Some prediction examples:\n",
    "prediction = sess.run(final_prediction,{data: test_input_ab, target: test_target_c})\n",
    "print test_input_ab[59]\n",
    "print test_target_c[59]\n",
    "print prediction[59]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
