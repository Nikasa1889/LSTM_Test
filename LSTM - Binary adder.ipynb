{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "#add binary string a, and b to create c.\n",
    "def add(a, b):\n",
    "    l = max(len(a), len(b));\n",
    "    a = int(a, 2);\n",
    "    b = int(b, 2);\n",
    "    c = bin(a+b)[2:].zfill(l);\n",
    "    return c;\n",
    "\n",
    "def str2np(a):\n",
    "    result = [int(x) for x in a]\n",
    "    return result;\n",
    "\n",
    "def lstofstr2tensor(lstofstr):\n",
    "    tensor = [str2np(string) for string in lstofstr]\n",
    "    return tensor\n",
    "\n",
    "def merge_str2list(str1, str2):\n",
    "    result = [[int(str1[i]), int(str2[i])] for i in xrange(len(str1))]\n",
    "    return result\n",
    "N_bit = 15;\n",
    "#To prevent overloading bit on result, we only generate N_bit-1 string\n",
    "formatting_string = ('{0:0'+str(N_bit)+'b}')\n",
    "input_a = [formatting_string.format(i) for i in xrange(2**(N_bit-1))];\n",
    "input_b = [formatting_string.format(i) for i in xrange(2**(N_bit-1))];\n",
    "shuffle(input_a);\n",
    "shuffle(input_b);\n",
    "\n",
    "N_TOTAL = 2000;\n",
    "\n",
    "input_a = input_a[:N_TOTAL];\n",
    "input_b = input_b[:N_TOTAL];\n",
    "target_c = [add(input_a[i], input_b[i]) for i in xrange(N_TOTAL)];\n",
    "\n",
    "#Need to reverse the binary string, since we do the calculation from right to left\n",
    "input_a = [a[::-1] for a in input_a];\n",
    "input_b = [b[::-1] for b in input_b];\n",
    "target_c = [c[::-1] for c in target_c];\n",
    "\n",
    "#Merge string a and b to one input\n",
    "input_ab = [merge_str2list(input_a[i], input_b[i]) for i in xrange(N_TOTAL)];\n",
    "\n",
    "target_c = lstofstr2tensor(target_c);\n",
    "\n",
    "#Convert to numpy array\n",
    "input_ab = np.asarray(input_ab)\n",
    "target_c = np.asarray(target_c)\n",
    "\n",
    "#Split to training and testing dataset\n",
    "N_TRAIN = 1500;\n",
    "test_input_ab = input_ab[N_TRAIN:]\n",
    "test_target_c = target_c[N_TRAIN:] \n",
    "\n",
    "train_input_ab = input_ab[:N_TRAIN]\n",
    "train_target_c = target_c[:N_TRAIN] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tensorflow for LSTM\n",
    "#### First we define the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Placeholder for input and target, [Batch Size, Sequence Length, Input Dimension]\n",
    "data = tf.placeholder(tf.float32, [None, N_bit, 2])\n",
    "target = tf.placeholder(tf.float32, [None, N_bit])\n",
    "\n",
    "num_hidden = 5\n",
    "time_steps = N_bit\n",
    "\n",
    "lstmCell = tf.nn.rnn_cell.BasicLSTMCell(num_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "\n",
    "#sequence_length \n",
    "#unroll the LSTM network\n",
    "outputs, states = tf.nn.dynamic_rnn(cell=lstmCell, inputs=data, dtype=tf.float32)\n",
    "\n",
    "# Define weights\n",
    "out_size = 1;\n",
    "\n",
    "# Weights for each timestep output, using the same weight\n",
    "weight = tf.Variable(tf.truncated_normal([num_hidden, out_size], stddev=0.1))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[out_size]))\n",
    "\n",
    "outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "prediction = tf.sigmoid(tf.matmul(outputs, weight) + bias)\n",
    "prediction = tf.reshape(prediction, [-1, time_steps, out_size])\n",
    "prediction = tf.squeeze(prediction)\n",
    "\n",
    "cross_entropy = -tf.reduce_mean(target * tf.log(prediction) + (1-target)*tf.log(1-prediction))\n",
    "#cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#cross_entropy = -tf.reduce_sum(target * tf.log(prediction))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "minimize = optimizer.minimize(cross_entropy)\n",
    "\n",
    "final_prediction = prediction>0.5;\n",
    "mistakes = tf.not_equal(target>0.5, final_prediction) #careful when target is still float32\n",
    "error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then we execute the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0569939613342 s Epoch -  0\n",
      "0.103631019592 s Epoch -  1\n",
      "0.150403022766 s Epoch -  2\n",
      "0.196510076523 s Epoch -  3\n",
      "0.243072032928 s Epoch -  4\n",
      "0.289645910263 s Epoch -  5\n",
      "0.336657047272 s Epoch -  6\n",
      "0.382961034775 s Epoch -  7\n",
      "0.429735898972 s Epoch -  8\n",
      "0.475718975067 s Epoch -  9\n",
      "0.523159980774 s Epoch -  10\n",
      "0.56963801384 s Epoch -  11\n",
      "0.615669965744 s Epoch -  12\n",
      "0.662015914917 s Epoch -  13\n",
      "0.708580970764 s Epoch -  14\n",
      "0.755018949509 s Epoch -  15\n",
      "0.801244020462 s Epoch -  16\n",
      "0.84724187851 s Epoch -  17\n",
      "0.893456935883 s Epoch -  18\n",
      "0.939221858978 s Epoch -  19\n",
      "0.985409975052 s Epoch -  20\n",
      "1.03158593178 s Epoch -  21\n",
      "1.0776860714 s Epoch -  22\n",
      "1.12388586998 s Epoch -  23\n",
      "1.17010688782 s Epoch -  24\n",
      "1.21639609337 s Epoch -  25\n",
      "1.26229190826 s Epoch -  26\n",
      "1.30831503868 s Epoch -  27\n",
      "1.35465192795 s Epoch -  28\n",
      "1.40111088753 s Epoch -  29\n",
      "1.44819498062 s Epoch -  30\n",
      "1.49461507797 s Epoch -  31\n",
      "1.54043102264 s Epoch -  32\n",
      "1.58660387993 s Epoch -  33\n",
      "1.63269090652 s Epoch -  34\n",
      "1.67942905426 s Epoch -  35\n",
      "1.72639203072 s Epoch -  36\n",
      "1.77288603783 s Epoch -  37\n",
      "1.81874608994 s Epoch -  38\n",
      "1.86507701874 s Epoch -  39\n",
      "1.91176891327 s Epoch -  40\n",
      "1.95834302902 s Epoch -  41\n",
      "2.00551199913 s Epoch -  42\n",
      "2.05245900154 s Epoch -  43\n",
      "2.09920287132 s Epoch -  44\n",
      "2.14551901817 s Epoch -  45\n",
      "2.19190502167 s Epoch -  46\n",
      "2.23854994774 s Epoch -  47\n",
      "2.28538393974 s Epoch -  48\n",
      "2.33167004585 s Epoch -  49\n",
      "2.37819099426 s Epoch -  50\n",
      "2.42456007004 s Epoch -  51\n",
      "2.47099900246 s Epoch -  52\n",
      "2.51775193214 s Epoch -  53\n",
      "2.56449508667 s Epoch -  54\n",
      "2.61119103432 s Epoch -  55\n",
      "2.65830898285 s Epoch -  56\n",
      "2.70504808426 s Epoch -  57\n",
      "2.75154399872 s Epoch -  58\n",
      "2.79782605171 s Epoch -  59\n",
      "2.84559488297 s Epoch -  60\n",
      "2.89228200912 s Epoch -  61\n",
      "2.93843197823 s Epoch -  62\n",
      "2.98427891731 s Epoch -  63\n",
      "3.03010797501 s Epoch -  64\n",
      "3.0770778656 s Epoch -  65\n",
      "3.12351608276 s Epoch -  66\n",
      "3.17034387589 s Epoch -  67\n",
      "3.21700501442 s Epoch -  68\n",
      "3.26331090927 s Epoch -  69\n",
      "3.30993700027 s Epoch -  70\n",
      "3.35698604584 s Epoch -  71\n",
      "3.40397286415 s Epoch -  72\n",
      "3.45057296753 s Epoch -  73\n",
      "3.49700593948 s Epoch -  74\n",
      "3.544039011 s Epoch -  75\n",
      "3.59033107758 s Epoch -  76\n",
      "3.63651394844 s Epoch -  77\n",
      "3.68263697624 s Epoch -  78\n",
      "3.72920203209 s Epoch -  79\n",
      "3.77566599846 s Epoch -  80\n",
      "3.82201504707 s Epoch -  81\n",
      "3.86836695671 s Epoch -  82\n",
      "3.91497707367 s Epoch -  83\n",
      "3.9609670639 s Epoch -  84\n",
      "4.00711798668 s Epoch -  85\n",
      "4.05331301689 s Epoch -  86\n",
      "4.0998840332 s Epoch -  87\n",
      "4.14581894875 s Epoch -  88\n",
      "4.19164800644 s Epoch -  89\n",
      "4.23782587051 s Epoch -  90\n",
      "4.28403091431 s Epoch -  91\n",
      "4.32994389534 s Epoch -  92\n",
      "4.37583994865 s Epoch -  93\n",
      "4.4216799736 s Epoch -  94\n",
      "4.46765398979 s Epoch -  95\n",
      "4.51376986504 s Epoch -  96\n",
      "4.56007099152 s Epoch -  97\n",
      "4.60624408722 s Epoch -  98\n",
      "4.65222787857 s Epoch -  99\n",
      "4.69910597801 s Epoch -  100\n",
      "4.7460360527 s Epoch -  101\n",
      "4.79267406464 s Epoch -  102\n",
      "4.83917498589 s Epoch -  103\n",
      "4.88575387001 s Epoch -  104\n",
      "4.93393206596 s Epoch -  105\n",
      "4.98107194901 s Epoch -  106\n",
      "5.02735805511 s Epoch -  107\n",
      "5.07368206978 s Epoch -  108\n",
      "5.1201210022 s Epoch -  109\n",
      "5.16688990593 s Epoch -  110\n",
      "5.21343588829 s Epoch -  111\n",
      "5.2598900795 s Epoch -  112\n",
      "5.30595397949 s Epoch -  113\n",
      "5.35184693336 s Epoch -  114\n",
      "5.3981320858 s Epoch -  115\n",
      "5.44448590279 s Epoch -  116\n",
      "5.49127197266 s Epoch -  117\n",
      "5.53768396378 s Epoch -  118\n",
      "5.5844938755 s Epoch -  119\n",
      "5.63139104843 s Epoch -  120\n",
      "5.67788887024 s Epoch -  121\n",
      "5.72392392159 s Epoch -  122\n",
      "5.77023386955 s Epoch -  123\n",
      "5.81688499451 s Epoch -  124\n",
      "5.86354708672 s Epoch -  125\n",
      "5.91033792496 s Epoch -  126\n",
      "5.95670104027 s Epoch -  127\n",
      "6.00335288048 s Epoch -  128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9f54b893e8cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_input_ab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mptr\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#print(sess.run(cross_entropy,{data: inp, target: out}))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "no_of_batches = int(len(train_input_ab)/BATCH_SIZE)\n",
    "epoch = 200\n",
    "start = time.time();\n",
    "for i in range(epoch):\n",
    "    ptr = 0\n",
    "    for j in range(no_of_batches):\n",
    "        inp, out = train_input_ab[ptr:ptr+BATCH_SIZE], train_target_c[ptr:ptr+BATCH_SIZE]\n",
    "        ptr+=BATCH_SIZE\n",
    "        sess.run(minimize,{data: inp, target: out})\n",
    "        \n",
    "        #print(sess.run(cross_entropy,{data: inp, target: out}))\n",
    "    print str(time.time()-start), \"s Epoch - \", str(i);\n",
    "incorrect = sess.run(error,{data: test_input_ab, target: test_target_c})\n",
    "print('Epoch {:2d} error {:3.1f}%'.format(i + 1, 100 * incorrect))\n",
    "prediction = sess.run(final_prediction,{data: test_input_ab, target: test_target_c})\n",
    "prediction.astype(int)\n",
    "\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]]\n",
      "[0 1 1 0 0 0 1 0 0 0 1 0 1 0 1]\n",
      "[False  True  True False False False  True False False False  True False\n",
      "  True False  True]\n"
     ]
    }
   ],
   "source": [
    "#Some prediction examples:\n",
    "prediction = sess.run(final_prediction,{data: test_input_ab, target: test_target_c})\n",
    "print test_input_ab[59]\n",
    "print test_target_c[59]\n",
    "print prediction[59]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
